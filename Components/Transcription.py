# Components/Transcription.py
"""
=============================================================================
TRANSCRI√á√ÉO MELHORADA COM DETEC√á√ÉO DE RISADAS
=============================================================================

ALTERA√á√ïES NESTA VERS√ÉO:
  - Detecta picos de √°udio (risadas, gritos)
  - Adiciona marcadores "[RISO]" na transcri√ß√£o
  - Ajuda o GPT a identificar momentos engra√ßados

COMO FUNCIONA:
  1. Whisper transcreve o √°udio
  2. Analisa amplitude do √°udio para detectar picos
  3. Marca momentos com volume alto como poss√≠veis risadas
  4. Retorna transcri√ß√£o enriquecida

=============================================================================
"""

import os
import whisper
import torch
import numpy as np
import librosa

def transcribeAudio(audio_file):
    """
    Transcreve √°udio usando Whisper e detecta risadas/rea√ß√µes por picos de √°udio.
    
    Returns:
        Lista de tuplas: (palavra, start_time, end_time)
    """
    print("üé§ Transcrevendo √°udio (PT-BR + timestamps por palavra)...")
    
    # Verificar CUDA
    device = "cuda" if torch.cuda.is_available() else "cpu"
    if device == "cuda":
        print("   ‚ö° GPU detectada - transcrevendo com CUDA")
    else:
        print("   üíª GPU n√£o detectada - usando CPU (mais lento)")
    
    # Carregar modelo Whisper
    model = whisper.load_model("base", device=device)
    
    # Transcrever com word timestamps
    result = model.transcribe(
        audio_file,
        language="pt",
        word_timestamps=True,
        temperature=0.0,
        condition_on_previous_text=True,
        initial_prompt="Esta √© uma live de gameplay com coment√°rios, risadas e rea√ß√µes emocionadas."
    )
    
    # Detectar picos de √°udio (poss√≠veis risadas/gritos)
    laugh_times = _detect_audio_peaks(audio_file)
    
    # Extrair palavras com timestamps
    transcriptions = []
    for segment in result["segments"]:
        if "words" not in segment:
            continue
            
        for word_data in segment["words"]:
            word = word_data.get("word", "").strip()
            start = float(word_data.get("start", 0))
            end = float(word_data.get("end", 0))
            
            if not word:
                continue
            
            # Verificar se est√° pr√≥ximo de um pico de √°udio
            if _is_near_laugh(start, laugh_times):
                # Adiciona marcador de riso
                word = f"[RISO] {word}"
            
            transcriptions.append((word, start, end))
    
    print(f"‚úÖ Transcri√ß√£o: {len(transcriptions)} palavras")
    print(f"   üòÇ {len(laugh_times)} poss√≠veis risadas/rea√ß√µes detectadas")
    
    return transcriptions


def _detect_audio_peaks(audio_file, threshold_percentile=85):
    """
    Detecta picos de amplitude no √°udio (poss√≠veis risadas, gritos, rea√ß√µes).
    
    Args:
        audio_file: Caminho do arquivo de √°udio
        threshold_percentile: Percentil para considerar um pico (85 = top 15%)
    
    Returns:
        Lista de timestamps onde h√° picos de √°udio
    """
    try:
        # Carregar √°udio
        y, sr = librosa.load(audio_file, sr=16000)
        
        # Calcular envelope de amplitude (RMS)
        hop_length = sr // 10  # 0.1s de resolu√ß√£o
        rms = librosa.feature.rms(y=y, hop_length=hop_length)[0]
        
        # Calcular threshold din√¢mico
        threshold = np.percentile(rms, threshold_percentile)
        
        # Encontrar picos
        peak_frames = np.where(rms > threshold)[0]
        
        # Converter frames para timestamps
        peak_times = librosa.frames_to_time(peak_frames, sr=sr, hop_length=hop_length)
        
        # Agrupar picos pr√≥ximos (< 2s de dist√¢ncia)
        grouped_peaks = []
        if len(peak_times) > 0:
            current_peak = peak_times[0]
            for t in peak_times[1:]:
                if t - current_peak > 2.0:  # Gap de 2s
                    grouped_peaks.append(current_peak)
                    current_peak = t
            grouped_peaks.append(current_peak)
        
        return grouped_peaks
        
    except Exception as e:
        print(f"   ‚ö†Ô∏è Erro ao detectar picos de √°udio: {e}")
        return []


def _is_near_laugh(timestamp, laugh_times, tolerance=1.5):
    """
    Verifica se um timestamp est√° pr√≥ximo de um pico de √°udio.
    
    Args:
        timestamp: Tempo da palavra
        laugh_times: Lista de tempos onde h√° picos
        tolerance: Dist√¢ncia m√°xima em segundos
    
    Returns:
        True se estiver pr√≥ximo de um pico
    """
    for laugh_time in laugh_times:
        if abs(timestamp - laugh_time) <= tolerance:
            return True
    return False
