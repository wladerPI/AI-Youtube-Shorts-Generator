# Components/SegmentSelectorLLM.py
"""
=============================================================================
SELETOR DE SEGMENTOS COM LLM (GPT)
=============================================================================

‚ö†Ô∏è PROBLEMA IDENTIFICADO:
Esta √© a camada que MATA a maioria dos clips!

FLUXO ATUAL:
1. LanguageTasks.py retorna 84 clips com dura√ß√£o for√ßada (45-180s) ‚úÖ
2. Este arquivo chama merge_coherent_segments() 
3. merge_coherent_segments REJEITA quase todos ‚ùå
4. Resultado: 84 clips ‚Üí 0 clips finais

POR QUE merge_coherent_segments REJEITA?
- Tenta "expandir" clips para incluir contexto completo
- Mas LanguageTasks.py j√° fez isso!
- Acaba duplicando l√≥gica e criando conflitos
- Par√¢metros (gap_tolerance, context_padding) muito restritivos

üîß SOLU√á√ÉO IMPLEMENTADA (tempor√°ria):
- Bypass do merge_coherent_segments
- Usa clips direto do LanguageTasks.py
- Filtro simples por dura√ß√£o

‚ö†Ô∏è PROBLEMA DESSA SOLU√á√ÉO:
- Perde valida√ß√£o de contexto
- Pode gerar clips que cortam frases no meio

‚úÖ SOLU√á√ÉO IDEAL (futuro):
- Remover merge_coherent_segments completamente
- Mover toda l√≥gica de contexto para LanguageTasks.py
- OU criar novo componente simples de valida√ß√£o
- Usar an√°lise de transcri√ß√£o para garantir frases completas

=============================================================================
"""

import json
import os
from dotenv import load_dotenv
load_dotenv()

from Components.LanguageTasks import GetHighlights


def _build_transcript_with_timestamps(transcriptions, interval_sec=15):
    """
    Converte transcri√ß√£o em texto com timestamps [MM:SS].
    
    FUNCIONA BEM - N√£o precisa de altera√ß√µes.
    
    FORMATO DE SA√çDA:
    [0:00] palavra palavra palavra
    [0:15] palavra palavra palavra
    [0:30] palavra palavra palavra
    
    NOTA: interval_sec=15 significa agrupar palavras a cada 15s
    CONSIDERA√á√ÉO: Testar com 10s ou 20s para ver impacto
    """
    if not transcriptions:
        return ""

    lines = []
    current_time = 0
    current_words = []

    for word, start, end in transcriptions:
        if start >= current_time + interval_sec and current_words:
            ts = int(current_time)
            lines.append(f"[{ts//60}:{ts%60:02d}] {' '.join(current_words)}")
            current_time = int(start / interval_sec) * interval_sec
            current_words = []
        current_words.append(word)

    if current_words:
        ts = int(current_time)
        lines.append(f"[{ts//60}:{ts%60:02d}] {' '.join(current_words)}")

    return "\n".join(lines)


def select_segments_with_llm(
    transcriptions,
    max_segments=25,
    min_duration=30,
    max_duration=180,
    prefer_llm=True,
    video_duration_min=240
):
    """
    FUN√á√ÉO PRINCIPAL - SELE√á√ÉO DE SEGMENTOS
    
    VERS√ÉO ATUAL (simplificada):
    1. Chama GetHighlights (retorna clips j√° expandidos)
    2. Filtra por dura√ß√£o
    3. Retorna direto (sem merge_coherent_segments)
    
    ‚ö†Ô∏è PROBLEMA: Muito simplista
    ‚ö†Ô∏è PROBLEMA: N√£o valida qualidade dos clips
    
    üîß MELHORIAS NECESS√ÅRIAS:
    1. Validar que clips t√™m palavras suficientes
    2. Verificar que n√£o cortam frases no meio
    3. Calcular score de qualidade (contexto, densidade de palavras, etc)
    4. Ordenar por score antes de retornar
    5. Adicionar deduplica√ß√£o inteligente (n√£o s√≥ por gap temporal)
    
    PAR√ÇMETROS:
    - max_segments: M√°ximo de clips a retornar
    - min_duration: Dura√ß√£o m√≠nima em segundos (padr√£o: 30s)
    - max_duration: Dura√ß√£o m√°xima em segundos (padr√£o: 180s)
    - prefer_llm: Se True, usa GPT. Se False, usa heur√≠stica
    - video_duration_min: Dura√ß√£o total do v√≠deo (para c√°lculo de quantos clips pedir)
    
    RETORNO:
    Lista de dicts: [{"start": 100.0, "end": 160.0, "reason": "fail √©pico", "score": 1.0}, ...]
    """
    transcript_text = _build_transcript_with_timestamps(transcriptions, interval_sec=20)

    if not transcript_text.strip():
        return []

    if prefer_llm and (os.getenv("OPENAI_API_KEY") or os.getenv("OPENAI_API")):
        try:
            # CHAMADA PRINCIPAL: GetHighlights
            highlights = GetHighlights(transcript_text, video_duration_min=video_duration_min)
            
            if not highlights:
                print("‚ö†Ô∏è GetHighlights retornou 0 clips")
                # Fallback para m√©todo heur√≠stico (sem GPT)
                return _fallback_heuristic(transcriptions, max_segments, min_duration, max_duration)
            
            # BYPASS DO merge_coherent_segments (estava rejeitando tudo)
            print(f"‚úÖ Usando {len(highlights)} clips direto do GPT")
            
            # Filtro simples por dura√ß√£o
            valid_segments = []
            for h in highlights:
                duration = h["end"] - h["start"]
                
                # Valida√ß√£o b√°sica
                if min_duration <= duration <= max_duration:
                    valid_segments.append(h)
                else:
                    # LOG: Por que foi rejeitado
                    # MELHORIA: Salvar isso em arquivo de log
                    if duration < min_duration:
                        pass  # Muito curto
                    else:
                        pass  # Muito longo
            
            print(f"‚úÖ {len(valid_segments)} clips passaram no filtro de dura√ß√£o")
            
            # MELHORIA FUTURA: Ordenar por score antes de limitar
            # valid_segments = sorted(valid_segments, key=lambda x: x.get("score", 0), reverse=True)
            
            # Limitar ao m√°ximo solicitado
            return valid_segments[:max_segments]
            
        except Exception as e:
            print(f"‚ö†Ô∏è LLM falhou ({e}) ‚Äî usando fallback heur√≠stico")
            # Em caso de erro, usar m√©todo heur√≠stico

    return _fallback_heuristic(transcriptions, max_segments, min_duration, max_duration)


def _fallback_heuristic(transcriptions, max_seg, min_dur, max_dur):
    """
    M√©todo heur√≠stico (sem GPT) para sele√ß√£o de clips.
    
    QUANDO √â USADO:
    - Quando prefer_llm=False
    - Quando n√£o h√° OPENAI_API_KEY
    - Quando GPT falha/crasheia
    
    COMO FUNCIONA:
    - Usa AISegmentSelector (baseado em palavras-chave)
    - Busca por densidade de palavras interessantes
    - N√£o usa IA, apenas regex e contagem
    
    ‚ö†Ô∏è PROBLEMA: Muito menos preciso que GPT
    ‚ö†Ô∏è PROBLEMA: N√£o detecta contexto ou humor
    
    ‚úÖ VANTAGEM: R√°pido, gratuito, sempre funciona
    
    CONSIDERA√á√ÉO: Melhorar heur√≠stica com:
    - An√°lise de picos de √°udio
    - Detec√ß√£o de mudan√ßas de tom
    - Contagem de marcadores [RISO]
    """
    try:
        from Components.AISegmentSelector import select_best_segments
        
        # NOTA: mode="RELAXED" aceita mais clips
        # Outros modos: "STRICT", "BALANCED"
        raw = select_best_segments(transcriptions, mode="RELAXED")
        
        # Filtrar por dura√ß√£o e limitar quantidade
        filtered = [
            {"start": s["start"], "end": s["end"], "reason": s.get("reason", "")}
            for s in raw[:max_seg * 2]  # Pega o dobro e filtra
            if min_dur <= (s["end"] - s["start"]) <= max_dur
        ][:max_seg]  # Limita ao m√°ximo
        
        return filtered
        
    except Exception as e:
        print(f"‚ö†Ô∏è Fallback tamb√©m falhou: {e}")
        return []


# =============================================================================
# PR√ìXIMOS PASSOS E MELHORIAS
# =============================================================================

"""
üî¥ CR√çTICO (fazer primeiro):
1. Decidir: merge_coherent_segments fica ou sai?
   - Se fica: Consertar par√¢metros
   - Se sai: Melhorar valida√ß√£o aqui

2. Implementar logging detalhado:
   - Quantos clips foram rejeitados em cada etapa
   - Por que foram rejeitados (muito curto, muito longo, etc)
   - Salvar em arquivo log/selection_{session}.txt

3. Adicionar valida√ß√£o de qualidade:
   - Verificar densidade de palavras
   - Checar se corta frase no meio
   - Calcular score baseado em m√∫ltiplos fatores

üü° IMPORTANTE (pr√≥xima itera√ß√£o):
1. Ordena√ß√£o inteligente por score
2. Deduplica√ß√£o baseada em conte√∫do (n√£o s√≥ tempo)
3. Distribui√ß√£o uniforme ao longo da live
4. Priorizar primeiros 30min (hook melhor)

üü¢ DESEJ√ÅVEL (longo prazo):
1. Sistema de cache (n√£o reprocessar mesma live)
2. Integra√ß√£o com sistema de feedback
3. ML para aprender prefer√™ncias
4. A/B testing de diferentes estrat√©gias

D√öVIDAS A RESOLVER:
- merge_coherent_segments √© realmente necess√°rio?
- Devemos confiar 100% no GPT ou adicionar valida√ß√£o?
- Como balancear quantidade vs qualidade?
- Vale a pena implementar heur√≠stica melhor ou focar no GPT?
"""
