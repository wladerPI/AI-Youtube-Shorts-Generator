# run_pipeline.py
"""
=============================================================================
PIPELINE PRINCIPAL ‚Äî LIVE ‚Üí SHORTS VIRAIS
=============================================================================

‚ö†Ô∏è PROBLEMAS ATUAIS DO PIPELINE:

1. FILTROS MUITO AGRESSIVOS
   - _deduplicate_segments com min_gap=60s mata muitos clips
   - filter_by_time_distance tamb√©m muito restritivo
   - Resultado: 544 highlights ‚Üí 4 shorts finais ‚ùå

2. PROCESSAMENTO SEQUENCIAL LENTO
   - Processa 1 clip por vez
   - Live de 5h demora ~2-3 horas para processar

3. SEM FEEDBACK DO USU√ÅRIO
   - Gera todos os shorts sem mostrar pr√©via

4. DEPEND√äNCIA CR√çTICA DO GPT
   - Se GPT falhar, todo pipeline falha

üîß MELHORIAS PRIORIT√ÅRIAS:

CURTO PRAZO:
1. Remover/relaxar filtros agressivos
2. Adicionar logs detalhados
3. Implementar modo preview

M√âDIO PRAZO:
1. Paralelizar processamento
2. Adicionar checkpoint/resume
3. Cache de transcri√ß√µes

LONGO PRAZO:
1. An√°lise de √°udio sem GPT
2. Sistema de ML para prefer√™ncias
3. Dashboard com m√©tricas

=============================================================================
"""

import sys
import os
import uuid
import re
import json

PIPELINE_MODE = "LIVE"
DRY_RUN = False
USE_LLM_SELECTION = True

print("üö® PIPELINE EXECUTANDO üö®")
print("=" * 60)

from Components.Edit import extractAudio, crop_video
from Components.Transcription import transcribeAudio
from Components.EtapaJ_RemoveSilence import remove_silence
from Components.SegmentSelectorLLM import select_segments_with_llm
from Components.TemporalFilter import filter_by_time_distance
from Components.ViralScore import calculate_viral_score
from Components.AttentionCurve import build_attention_curve
from Components.RetentionScore import calculate_retention_metrics
from Components.SmartRanking import calculate_rank_score
from Components.SubtitleGenerator import generate_srt
from Render.VerticalCropper import render_vertical_video
from Components.PipelineConfig import get_pipeline_config

config = get_pipeline_config(PIPELINE_MODE)
MAX_SHORTS = config["MAX_SHORTS"]
MIN_RETENTION = config["MIN_RETENTION"]
MIN_VIRAL = config["MIN_VIRAL"]


def clean_filename(name):
    """Limpa nome de arquivo."""
    name = name.lower()
    name = re.sub(r'[<>:"/\\|?*]', '', name)
    name = re.sub(r'\s+', '-', name)
    return name[:80]


def _deduplicate_segments(segments, min_gap=60):
    """
    ‚ö†Ô∏è PROBLEMA CR√çTICO: min_gap=60s √© MUITO RESTRITIVO!
    
    SOLU√á√ÉO SUGERIDA: Reduzir para 20-30s ou remover completamente
    """
    if not segments:
        return []
    
    segs = sorted(segments, key=lambda s: float(s["start"]))
    out = [segs[0]]
    
    for s in segs[1:]:
        last = out[-1]
        last_end = float(last["end"])
        s_start = float(s["start"])
        
        if s_start < last_end:
            continue
        
        if s_start - last_end < min_gap:
            continue  # ‚Üê AQUI que mata 90% dos clips!
        
        out.append(s)
    
    return out


def main():
    """Fun√ß√£o principal do pipeline."""
    
    if len(sys.argv) < 2:
        print("‚ùå Uso: python run_pipeline.py input\\video.mp4")
        sys.exit(1)

    input_video = sys.argv[1]
    if not os.path.isfile(input_video):
        print("‚ùå V√≠deo n√£o encontrado")
        sys.exit(1)

    os.makedirs("clips", exist_ok=True)
    os.makedirs("shorts", exist_ok=True)
    os.makedirs("rankings", exist_ok=True)
    os.makedirs("input", exist_ok=True)

    session = str(uuid.uuid4())[:8]
    base_name = clean_filename(os.path.splitext(os.path.basename(input_video))[0])
    audio_file = f"audio_{session}.wav"

    # ETAPA 1: Extrair √°udio
    print("üéß Extraindo √°udio...")
    extractAudio(input_video, audio_file)

    # ETAPA 2: Transcrever
    print("üß† Transcrevendo...")
    transcriptions = transcribeAudio(audio_file)
    
    if not transcriptions:
        print("‚ùå Transcri√ß√£o vazia")
        return

    video_duration = max(t[2] for t in transcriptions) if transcriptions else 0
    video_duration_min = video_duration / 60
    print(f"üìä V√≠deo: {video_duration_min:.1f} minutos ({video_duration:.0f}s)")

    # ETAPA 3: Selecionar segmentos
    print("üß† Selecionando segmentos (rizadas, memes, rage)...")
    segments = select_segments_with_llm(
        transcriptions,
        max_segments=MAX_SHORTS,
        min_duration=45,
        max_duration=180,
        prefer_llm=USE_LLM_SELECTION,
        video_duration_min=video_duration_min
    )

    print(f"üìå Segmentos brutos encontrados: {len(segments)}")

    # ETAPA 4: Filtros (PROBLEMA: muito agressivos!)
    segments = _deduplicate_segments(segments, min_gap=60)
    print(f"üìå Ap√≥s deduplica√ß√£o: {len(segments)}")
    
    segments = filter_by_time_distance(segments, min_distance=60)
    print(f"üìå Ap√≥s filtro temporal: {len(segments)}")
    
    segments = segments[:MAX_SHORTS]
    print(f"üìå Segmentos finais: {len(segments)}")

    if not segments:
        print("‚ùå Nenhum segmento selecionado")
        return

    ranking = []

    # ETAPA 5: Processar cada segmento
    for idx, seg in enumerate(segments, 1):
        start = float(seg["start"])
        end = float(seg["end"])
        duration = end - start

        if duration < 30:
            continue

        reason = seg.get("reason", "sem motivo")
        print(f"\nüé¨ Clip {idx}/{len(segments)}: {start:.1f}s ‚Üí {end:.1f}s ({duration:.1f}s)")
        print(f"   üí° Motivo: {reason}")

        clip_path = f"clips/{base_name}_{idx}_{session}.mp4"
        short_path = f"shorts/{base_name}_SHORT_{idx}_{session}.mp4"
        temp_silence_path = clip_path.replace(".mp4", "_nosilence.mp4")

        if not DRY_RUN:
            crop_video(input_video, clip_path, start, end)
            remove_silence(video_in=clip_path, video_out=temp_silence_path)
            render_vertical_video(temp_silence_path, short_path, pan_engine=True)
            
            if os.path.exists(temp_silence_path):
                try:
                    os.remove(temp_silence_path)
                except Exception:
                    pass

        viral = calculate_viral_score(start, end, reason)
        curve = build_attention_curve(audio_file, duration)
        retention = calculate_retention_metrics(curve)

        score = calculate_rank_score({
            "viral_score": viral,
            "retention_score": retention["score"],
            "duration": duration,
            "drop_risk": retention.get("drop_risk", "medio")
        })

        generate_srt(
            transcriptions,
            clip_start=start,
            clip_end=end,
            output_path=short_path.replace(".mp4", ".srt")
        )

        ranking.append({
            "file": short_path,
            "start": start,
            "end": end,
            "duration": duration,
            "reason": reason,
            "viral": viral,
            "retention": retention["score"],
            "rank": score
        })

    ranking_sorted = sorted(ranking, key=lambda x: x["rank"], reverse=True)
    
    with open("rankings/ranking.json", "w", encoding="utf-8") as f:
        json.dump(ranking_sorted, f, indent=2, ensure_ascii=False)

    if os.path.exists(audio_file):
        os.remove(audio_file)

    print("\n" + "=" * 60)
    print("üéâ PIPELINE FINALIZADO üéâ")
    print(f"   üìä {len(ranking)} shorts gerados em shorts/")
    if ranking_sorted:
        print(f"   üèÜ Top 3 por ranking:")
        for i, r in enumerate(ranking_sorted[:3], 1):
            print(f"      {i}. {r['file'].split('/')[-1]} - Score: {r['rank']:.2f}")
    print("=" * 60)


if __name__ == "__main__":
    main()

"""
ROADMAP DE MELHORIAS:

üî¥ CR√çTICO:
1. Resolver filtros agressivos
2. Melhorar consist√™ncia do GPT
3. Adicionar logging detalhado

üü° IMPORTANTE:
1. Cachear transcri√ß√µes
2. Paralelizar renderiza√ß√£o
3. Modo preview

üü¢ DESEJ√ÅVEL:
1. UI web
2. An√°lise de √°udio sem GPT
3. Sistema de aprendizado

üîµ FUTURO:
1. M√∫ltiplas l√≠nguas
2. Detec√ß√£o de rostos
3. Upload autom√°tico
"""
