# run_pipeline.py
"""
=============================================================================
PIPELINE PRINCIPAL ‚Äî LIVE ‚Üí SHORTS VIRAIS
=============================================================================
CONTEXTO: Leia PROJECT_OVERVIEW.md para vis√£o geral do projeto.

O QUE FAZ:
  Orquestra todo o processo de transforma√ß√£o de uma live em m√∫ltiplos shorts:
  1. Extrai √°udio
  2. Transcreve com Whisper
  3. Seleciona segmentos via LLM (rizadas, memes, rage) ou heur√≠stica
  4. Remove sil√™ncios
  5. Renderiza vertical COM √ÅUDIO + pan para memes nos cantos
  6. Gera legendas SRT
  7. Salva ranking.json

COMO EXECUTAR:
  python run_pipeline.py input\\video.mp4

ALTERA√á√ïES REALIZADAS:
  - Troca de AISegmentSelector (heur√≠stico) para SegmentSelectorLLM (GPT)
  - Adi√ß√£o de _deduplicate_segments (evita Clip 1 e 5 serem iguais)
  - VerticalCropper passou a usar MoviePy (preserva √°udio)
  - Dura√ß√£o de segmentos: 30s a 3min (contexto completo)
  - Mais shorts por live: LIVE=25, INSANO=35

O QUE AINDA PODE SER FEITO:
  - Processar m√∫ltiplos v√≠deos em batch
  - Modo interativo para aprovar/rejeitar segmentos
  - Salvar progresso para retomada ap√≥s falha
  - Estimativa de tempo restante
=============================================================================
"""

import sys
import os
import uuid
import re
import json

# ---------------------------------------------------------------------------
# CONFIGURA√á√ïES DO PIPELINE
# ---------------------------------------------------------------------------
# LIVE = produ√ß√£o normal | TEST = poucos shorts para teste | INSANO = m√°ximo
PIPELINE_MODE = "LIVE"

# Se True, n√£o renderiza v√≠deos (apenas simula)
DRY_RUN = False

# True = usa GPT para detectar rizadas/memes | False = heur√≠stica (sem API)
USE_LLM_SELECTION = True

print("üö® PIPELINE EXECUTANDO üö®")
print("=" * 60)

# ---------------------------------------------------------------------------
# IMPORTS
# ---------------------------------------------------------------------------
from Components.Edit import extractAudio, crop_video
from Components.Transcription import transcribeAudio
from Components.EtapaJ_RemoveSilence import remove_silence
from Components.SegmentSelectorLLM import select_segments_with_llm
from Components.TemporalFilter import filter_by_time_distance
from Components.ViralScore import calculate_viral_score
from Components.AttentionCurve import build_attention_curve
from Components.RetentionScore import calculate_retention_metrics
from Components.SmartRanking import calculate_rank_score
from Components.SubtitleGenerator import generate_srt
from Render.VerticalCropper import render_vertical_video
from Components.PipelineConfig import get_pipeline_config

config = get_pipeline_config(PIPELINE_MODE)
MAX_SHORTS = config["MAX_SHORTS"]
MIN_RETENTION = config["MIN_RETENTION"]
MIN_VIRAL = config["MIN_VIRAL"]


def clean_filename(name):
    """
    Limpa nome de arquivo: min√∫sculo, sem caracteres inv√°lidos, h√≠fens no lugar de espa√ßos.
    Necess√°rio para nomes compat√≠veis com Windows/Linux.
    """
    name = name.lower()
    name = re.sub(r'[<>:"/\\|?*]', '', name)
    name = re.sub(r'\s+', '-', name)
    return name[:80]


def _deduplicate_segments(segments, min_gap=90):
    """
    Remove segmentos sobrepostos ou muito pr√≥ximos no tempo.
    
    POR QUE: Em execu√ß√µes anteriores, Clip 1 e Clip 5 eram o mesmo segmento
    (5129s-5170s). A deduplica√ß√£o evita shorts repetidos.
    
    min_gap: dist√¢ncia m√≠nima em segundos entre o fim de um e o in√≠cio do pr√≥ximo.
    """
    if not segments:
        return []
    segs = sorted(segments, key=lambda s: float(s["start"]))
    out = [segs[0]]
    for s in segs[1:]:
        last = out[-1]
        last_end = float(last["end"])
        s_start = float(s["start"])
        # Ignora se sobrep√µe
        if s_start < last_end:
            continue
        # Ignora se est√° muito pr√≥ximo
        if s_start - last_end < min_gap:
            continue
        out.append(s)
    return out


def main():
    # Validar argumentos
    if len(sys.argv) < 2:
        print("‚ùå Uso: python run_pipeline.py input\\video.mp4")
        sys.exit(1)

    input_video = sys.argv[1]
    if not os.path.isfile(input_video):
        print("‚ùå V√≠deo n√£o encontrado")
        sys.exit(1)

    # Criar pastas de sa√≠da
    os.makedirs("clips", exist_ok=True)
    os.makedirs("shorts", exist_ok=True)
    os.makedirs("rankings", exist_ok=True)
    os.makedirs("input", exist_ok=True)

    # ID √∫nico da sess√£o (permite m√∫ltiplas execu√ß√µes simult√¢neas)
    session = str(uuid.uuid4())[:8]
    base_name = clean_filename(os.path.splitext(os.path.basename(input_video))[0])
    audio_file = f"audio_{session}.wav"

    # ETAPA 1: Extrair √°udio (necess√°rio para transcri√ß√£o)
    print("üéß Extraindo √°udio...")
    extractAudio(input_video, audio_file)

    # ETAPA 2: Transcrever (Whisper retorna palavra + timestamp)
    print("üß† Transcrevendo...")
    transcriptions = transcribeAudio(audio_file)
    if not transcriptions:
        print("‚ùå Transcri√ß√£o vazia")
        return

    # Dura√ß√£o estimada do v√≠deo (para o LLM saber quantos momentos pedir)
    video_duration = max(t[2] for t in transcriptions) if transcriptions else 0
    video_duration_min = video_duration / 60

    # ETAPA 3: Selecionar segmentos (LLM ou heur√≠stica)
    print("üß† Selecionando segmentos (rizadas, memes, rage)...")
    segments = select_segments_with_llm(
        transcriptions,
        max_segments=MAX_SHORTS,
        min_duration=30,   # Shorts de no m√≠nimo 30s (contexto)
        max_duration=180,  # At√© 3min (usu√°rio ajusta no CapCut)
        prefer_llm=USE_LLM_SELECTION,
        video_duration_min=video_duration_min
    )

    # Deduplicar e filtrar por dist√¢ncia temporal
    segments = _deduplicate_segments(segments, min_gap=90)
    segments = filter_by_time_distance(segments, min_distance=90)
    segments = segments[:MAX_SHORTS]

    if not segments:
        print("‚ùå Nenhum segmento selecionado")
        return

    ranking = []

    # ETAPA 4: Processar cada segmento
    for idx, seg in enumerate(segments, 1):
        start = float(seg["start"])
        end = float(seg["end"])
        duration = end - start

        if duration < 15:
            continue

        print(f"üé¨ Clip {idx}: {start:.1f}s ‚Üí {end:.1f}s ({duration:.1f}s)")

        clip_path = f"clips/{base_name}_{idx}_{session}.mp4"
        short_path = f"shorts/{base_name}_SHORT_{idx}_{session}.mp4"
        temp_silence_path = clip_path.replace(".mp4", "_nosilence.mp4")

        if not DRY_RUN:
            # Cortar trecho do v√≠deo original
            crop_video(input_video, clip_path, start, end)
            # Remover sil√™ncios longos (reduz dura√ß√£o)
            remove_silence(
                video_in=clip_path,
                video_out=temp_silence_path
            )
            # Renderizar vertical COM √ÅUDIO + pan para memes
            render_vertical_video(
                temp_silence_path,
                short_path,
                pan_engine=True
            )
            # Limpar arquivo tempor√°rio
            if os.path.exists(temp_silence_path):
                try:
                    os.remove(temp_silence_path)
                except Exception:
                    pass

        # Calcular scores para ranking
        viral = calculate_viral_score(start, end, seg.get("reason", ""))
        curve = build_attention_curve(audio_file, duration)
        retention = calculate_retention_metrics(curve)

        score = calculate_rank_score({
            "viral_score": viral,
            "retention_score": retention["score"],
            "duration": duration,
            "drop_risk": retention.get("drop_risk", "medio")
        })

        # Gerar legendas SRT
        generate_srt(
            transcriptions,
            clip_start=start,
            clip_end=end,
            output_path=short_path.replace(".mp4", ".srt")
        )

        ranking.append({
            "file": short_path,
            "start": start,
            "end": end,
            "viral": viral,
            "retention": retention["score"],
            "rank": score
        })

    # Salvar ranking final
    with open("rankings/ranking.json", "w", encoding="utf-8") as f:
        json.dump(ranking, f, indent=2, ensure_ascii=False)

    # Limpar √°udio tempor√°rio
    if os.path.exists(audio_file):
        os.remove(audio_file)

    print("üî• PIPELINE FINALIZADO üî•")
    print(f"   {len(ranking)} shorts gerados em shorts/")


if __name__ == "__main__":
    main()
